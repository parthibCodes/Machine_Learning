{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd94a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 1.9784, b: 0.0280, cost: 5199.1000, iteration: 0\n",
      "m: 0.2098, b: 0.0030, cost: 4161.4824, iteration: 1\n",
      "m: 1.7908, b: 0.0254, cost: 3332.2237, iteration: 2\n",
      "m: 0.3774, b: 0.0055, cost: 2669.4844, iteration: 3\n",
      "m: 1.6410, b: 0.0234, cost: 2139.8264, iteration: 4\n",
      "m: 0.5114, b: 0.0075, cost: 1716.5264, iteration: 5\n",
      "m: 1.5212, b: 0.0218, cost: 1378.2272, iteration: 6\n",
      "m: 0.6184, b: 0.0091, cost: 1107.8602, iteration: 7\n",
      "m: 1.4255, b: 0.0205, cost: 891.7842, iteration: 8\n",
      "m: 0.7040, b: 0.0104, cost: 719.0974, iteration: 9\n",
      "m: 1.3490, b: 0.0195, cost: 581.0870, iteration: 10\n",
      "m: 0.7724, b: 0.0114, cost: 470.7897, iteration: 11\n",
      "m: 1.2879, b: 0.0187, cost: 382.6407, iteration: 12\n",
      "m: 0.8270, b: 0.0123, cost: 312.1925, iteration: 13\n",
      "m: 1.2390, b: 0.0181, cost: 255.8906, iteration: 14\n",
      "m: 0.8707, b: 0.0130, cost: 210.8944, iteration: 15\n",
      "m: 1.2000, b: 0.0177, cost: 174.9337, iteration: 16\n",
      "m: 0.9056, b: 0.0136, cost: 146.1941, iteration: 17\n",
      "m: 1.1687, b: 0.0173, cost: 123.2255, iteration: 18\n",
      "m: 0.9335, b: 0.0140, cost: 104.8691, iteration: 19\n",
      "m: 1.1438, b: 0.0171, cost: 90.1988, iteration: 20\n",
      "m: 0.9558, b: 0.0144, cost: 78.4744, iteration: 21\n",
      "m: 1.1239, b: 0.0169, cost: 69.1043, iteration: 22\n",
      "m: 0.9736, b: 0.0148, cost: 61.6157, iteration: 23\n",
      "m: 1.1079, b: 0.0167, cost: 55.6309, iteration: 24\n",
      "m: 0.9879, b: 0.0151, cost: 50.8478, iteration: 25\n",
      "m: 1.0952, b: 0.0166, cost: 47.0253, iteration: 26\n",
      "m: 0.9992, b: 0.0153, cost: 43.9703, iteration: 27\n",
      "m: 1.0850, b: 0.0166, cost: 41.5287, iteration: 28\n",
      "m: 1.0083, b: 0.0155, cost: 39.5775, iteration: 29\n",
      "m: 1.0769, b: 0.0165, cost: 38.0180, iteration: 30\n",
      "m: 1.0156, b: 0.0157, cost: 36.7717, iteration: 31\n",
      "m: 1.0704, b: 0.0165, cost: 35.7757, iteration: 32\n",
      "m: 1.0214, b: 0.0159, cost: 34.9797, iteration: 33\n",
      "m: 1.0652, b: 0.0166, cost: 34.3435, iteration: 34\n",
      "m: 1.0261, b: 0.0160, cost: 33.8350, iteration: 35\n",
      "m: 1.0611, b: 0.0166, cost: 33.4287, iteration: 36\n",
      "m: 1.0298, b: 0.0162, cost: 33.1039, iteration: 37\n",
      "m: 1.0577, b: 0.0166, cost: 32.8444, iteration: 38\n",
      "m: 1.0327, b: 0.0163, cost: 32.6370, iteration: 39\n",
      "m: 1.0551, b: 0.0167, cost: 32.4712, iteration: 40\n",
      "m: 1.0351, b: 0.0164, cost: 32.3387, iteration: 41\n",
      "m: 1.0530, b: 0.0167, cost: 32.2328, iteration: 42\n",
      "m: 1.0370, b: 0.0166, cost: 32.1482, iteration: 43\n",
      "m: 1.0513, b: 0.0168, cost: 32.0806, iteration: 44\n",
      "m: 1.0385, b: 0.0167, cost: 32.0265, iteration: 45\n",
      "m: 1.0499, b: 0.0169, cost: 31.9833, iteration: 46\n",
      "m: 1.0397, b: 0.0168, cost: 31.9488, iteration: 47\n",
      "m: 1.0488, b: 0.0169, cost: 31.9212, iteration: 48\n",
      "m: 1.0407, b: 0.0169, cost: 31.8991, iteration: 49\n",
      "m: 1.0480, b: 0.0170, cost: 31.8815, iteration: 50\n",
      "m: 1.0414, b: 0.0170, cost: 31.8674, iteration: 51\n",
      "m: 1.0473, b: 0.0171, cost: 31.8561, iteration: 52\n",
      "m: 1.0421, b: 0.0171, cost: 31.8471, iteration: 53\n",
      "m: 1.0467, b: 0.0172, cost: 31.8399, iteration: 54\n",
      "m: 1.0426, b: 0.0172, cost: 31.8342, iteration: 55\n",
      "m: 1.0463, b: 0.0172, cost: 31.8296, iteration: 56\n",
      "m: 1.0429, b: 0.0172, cost: 31.8259, iteration: 57\n",
      "m: 1.0459, b: 0.0173, cost: 31.8230, iteration: 58\n",
      "m: 1.0433, b: 0.0173, cost: 31.8206, iteration: 59\n",
      "m: 1.0456, b: 0.0174, cost: 31.8187, iteration: 60\n",
      "m: 1.0435, b: 0.0174, cost: 31.8172, iteration: 61\n",
      "m: 1.0454, b: 0.0175, cost: 31.8160, iteration: 62\n",
      "m: 1.0437, b: 0.0175, cost: 31.8151, iteration: 63\n",
      "m: 1.0452, b: 0.0176, cost: 31.8143, iteration: 64\n",
      "m: 1.0439, b: 0.0176, cost: 31.8137, iteration: 65\n",
      "m: 1.0451, b: 0.0177, cost: 31.8132, iteration: 66\n",
      "m: 1.0440, b: 0.0177, cost: 31.8128, iteration: 67\n",
      "m: 1.0450, b: 0.0178, cost: 31.8124, iteration: 68\n",
      "m: 1.0441, b: 0.0178, cost: 31.8122, iteration: 69\n",
      "m: 1.0449, b: 0.0178, cost: 31.8120, iteration: 70\n",
      "m: 1.0442, b: 0.0179, cost: 31.8118, iteration: 71\n",
      "m: 1.0448, b: 0.0179, cost: 31.8117, iteration: 72\n",
      "m: 1.0442, b: 0.0180, cost: 31.8116, iteration: 73\n",
      "m: 1.0447, b: 0.0180, cost: 31.8115, iteration: 74\n",
      "m: 1.0443, b: 0.0180, cost: 31.8114, iteration: 75\n",
      "m: 1.0447, b: 0.0181, cost: 31.8113, iteration: 76\n",
      "m: 1.0443, b: 0.0181, cost: 31.8113, iteration: 77\n",
      "m: 1.0447, b: 0.0182, cost: 31.8112, iteration: 78\n",
      "m: 1.0444, b: 0.0182, cost: 31.8112, iteration: 79\n",
      "m: 1.0446, b: 0.0183, cost: 31.8112, iteration: 80\n",
      "m: 1.0444, b: 0.0183, cost: 31.8111, iteration: 81\n",
      "m: 1.0446, b: 0.0184, cost: 31.8111, iteration: 82\n",
      "m: 1.0444, b: 0.0184, cost: 31.8111, iteration: 83\n",
      "m: 1.0446, b: 0.0184, cost: 31.8111, iteration: 84\n",
      "m: 1.0444, b: 0.0185, cost: 31.8111, iteration: 85\n",
      "m: 1.0446, b: 0.0185, cost: 31.8111, iteration: 86\n",
      "m: 1.0444, b: 0.0186, cost: 31.8110, iteration: 87\n",
      "m: 1.0445, b: 0.0186, cost: 31.8110, iteration: 88\n",
      "m: 1.0445, b: 0.0187, cost: 31.8110, iteration: 89\n",
      "m: 1.0445, b: 0.0187, cost: 31.8110, iteration: 90\n",
      "m: 1.0445, b: 0.0187, cost: 31.8110, iteration: 91\n",
      "m: 1.0445, b: 0.0188, cost: 31.8110, iteration: 92\n",
      "m: 1.0445, b: 0.0188, cost: 31.8110, iteration: 93\n",
      "m: 1.0445, b: 0.0189, cost: 31.8110, iteration: 94\n",
      "m: 1.0445, b: 0.0189, cost: 31.8110, iteration: 95\n",
      "m: 1.0445, b: 0.0190, cost: 31.8109, iteration: 96\n",
      "m: 1.0445, b: 0.0190, cost: 31.8109, iteration: 97\n",
      "m: 1.0445, b: 0.0191, cost: 31.8109, iteration: 98\n",
      "m: 1.0445, b: 0.0191, cost: 31.8109, iteration: 99\n",
      "\n",
      "Using gradient descent: Coef = 1.0445, Intercept = 0.0191\n",
      "Using sklearn: Coef = 1.0177, Intercept = 1.9152\n"
     ]
    }
   ],
   "source": [
    "def predict_using_sklearn():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\parth\\\\OneDrive\\\\Desktop\\\\ML_CSV\\\\test_scores.csv\")\n",
    "    r = LinearRegression()\n",
    "    r.fit(df[['math']], df['cs'])\n",
    "    return r.coef_[0], r.intercept_\n",
    "\n",
    "def gradient_descent(x, y):\n",
    "    m_curr = 0\n",
    "    b_curr = 0\n",
    "    iterations = 100000\n",
    "    n = len(x)\n",
    "    learning_rate = 0.0002\n",
    "\n",
    "    cost_previous = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n) * sum((y - y_predicted) ** 2)\n",
    "        md = -(2/n) * sum(x * (y - y_predicted))\n",
    "        bd = -(2/n) * sum(y - y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "\n",
    "        if math.isclose(cost, cost_previous, rel_tol=1e-9):  # Relaxed tolerance\n",
    "            break\n",
    "        cost_previous = cost\n",
    "\n",
    "        print(f\"m: {m_curr:.4f}, b: {b_curr:.4f}, cost: {cost:.4f}, iteration: {i}\")\n",
    "\n",
    "    return m_curr, b_curr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\parth\\\\OneDrive\\\\Desktop\\\\ML_CSV\\\\test_scores.csv\")\n",
    "    x = np.array(df['math'])\n",
    "    y = np.array(df['cs'])\n",
    "\n",
    "    m, b = gradient_descent(x, y)\n",
    "    print(\"\\nUsing gradient descent: Coef = {:.4f}, Intercept = {:.4f}\".format(m, b))\n",
    "\n",
    "    m_sklearn, b_sklearn = predict_using_sklearn()\n",
    "    print(\"Using sklearn: Coef = {:.4f}, Intercept = {:.4f}\".format(m_sklearn, b_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
